# Hyperparameter tuning



* [Bayesian Optimization for Hyperparameter Tuning](https://arimo.com/data-science/2016/bayesian-optimization-hyperparameter-tuning/)
* [Hyperparameter Tuning with hyperopt in Python](http://steventhornton.ca/hyperparameter-tuning-with-hyperopt-in-python/)
* [Best Practices for Parameter Tuning on Models](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/discussion/19083)
* [Avoiding Grid for parameter tuning](https://www.kaggle.com/c/allstate-claims-severity/discussion/24532)
* [Bayesian Optimization XGBoost parameters](https://www.kaggle.com/tilii7/bayesian-optimization-xgboost-parameters)
* [XGboost + Bayesian Optimization](https://www.kaggle.com/tilii7/xgboost-bayesian-optimization/code)
* [SVR+sparse matrix+Bayesian optimization](https://www.kaggle.com/tilii7/svr-sparse-matrix-bayesian-optimization/)
* [Bayesian Optimization of a Technical Trading Algorithm with Zipline+SigOpt](https://blog.quantopian.com/bayesian-optimization-of-a-technical-trading-algorithm-with-ziplinesigopt-2/)
* [sklearn-gridsearchcv-replacement.ipynb](https://github.com/scikit-optimize/scikit-optimize/blob/master/examples/sklearn-gridsearchcv-replacement.ipynb)
* [BayesianOptimization/sklearn\_example.py](https://github.com/fmfn/BayesianOptimization/blob/master/examples/sklearn_example.py)
* [Hyper-parameter Optimization with keras?](https://github.com/fchollet/keras/issues/1591)
* [Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization](https://github.com/maxpumperla/hyperas)
* [Effectively running thousands of experiments: Hyperopt with Sacred](https://gab41.lab41.org/effectively-running-thousands-of-experiments-hyperopt-with-sacred-dfa53b50f1ec)
* [Hyperopt tutorial for Optimizing Neural Networks' Hyperparameters - Vooban](https://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/)
* [hyperopt\_experiments.py](https://github.com/Lab41/pythia/blob/master/experiments/hyperopt_experiments.py)
* [Spearmint](https://github.com/HIPS/Spearmint)
* [GPyOpt](https://sheffieldml.github.io/GPyOpt/) a Python open-source library for Bayesian Optimization
* [Scikit-Optimize](https://scikit-optimize.github.io/)
* [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/neural-networks-3/#hyper)
* [Hyperparameters tuning with Polyaxon – Polyaxon – Medium](https://medium.com/polyaxon/hyperparameters-tuning-with-polyaxon-9403f8ea85be)
* [zygmuntz/hyperband: Tuning hyperparams fast with Hyperband](https://github.com/zygmuntz/hyperband)

## Automated

[reiinakano/xcessiv: A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling in Python.](https://github.com/reiinakano/xcessiv)

[ClimbsRocks/auto\_ml: Automated machine learning for analytics & production](https://github.com/ClimbsRocks/auto_ml)

[Automatic model tuning with Sacred and Hyperopt.ipynb](https://github.com/gereleth/kaggle-telstra/blob/master/Automatic%20model%20tuning%20with%20Sacred%20and%20Hyperopt.ipynb)

