# Audit

* data privacy
  * GDPR
  * [_Private Aggregation of Teacher Ensembles_ \(PATE\)](http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html)
* metric appropriate?
* data leakage?
* train-test-split reasonable?
* Interpretability
  * [Natural Language Processing Is Fun Part 3: Explaining Model Predictions](https://medium.com/@ageitgey/natural-language-processing-is-fun-part-3-explaining-model-predictions-486d8616813c)
* fairness
* security
  * reverse engineering
*  integrity - adversaries \(Adversarial Reprogramming of Neural Networks\)
  * Adversarial training
  * Defensive distillation
  * " It is clear that **testing** of **naturally occurring inputs** is sufficient for traditional machine learning applications, but **verification** of **unusual inputs** is necessary for security guarantees. **We should verify, but so far we only know how to test**."
  *  **use `cleverhans` to test their models against standardized, state-of-the-art attacks**
* Poisoning training sets
* [The IIA’s Artificial Intelligence Auditing Framework](https://na.theiia.org/periodicals/Public%20Documents/GPI-Artificial-Intelligence-Part-III.pdf)
* [How to lie with Data Science – Towards Data Science](https://towardsdatascience.com/how-to-lie-with-data-science-5090f3891d9c)



