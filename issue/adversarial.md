# Adversarial

* [A Step-by-Step Guide to Synthesizing Adversarial Examples · cat /var/log/life](https://www.anishathalye.com/2017/07/25/synthesizing-adversarial-examples/)
* [tensorflow/cleverhans: An adversarial example library for constructing attacks, building defenses, and benchmarking both](https://github.com/tensorflow/cleverhans)
* [Breaking Linear Classifiers on ImageNet](http://karpathy.github.io/2015/03/30/breaking-convnets/)
* [\[1610.00768\] Technical Report on the CleverHans v2.1.0 Adversarial Examples Library](https://arxiv.org/abs/1610.00768)
* [Privacy and machine learning: two unexpected allies? \| cleverhans-blog](http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html)
* [The challenge of verification and testing of machine learning \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html)
* [Is attacking machine learning easier than defending it? \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html)
* [Breaking things is easy \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2016/12/16/breaking-things-is-easy.html)
* [Making Machine Learning Robust Against Adversarial Inputs \| July 2018 \| Communications of the ACM](https://cacm.acm.org/magazines/2018/7/229030-making-machine-learning-robust-against-adversarial-inputs/fulltext)
* [\[1412.6572\] Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)
* [Characterizing the Limits and Defenses of Machine Learning in Adversarial Settings](https://etda.libraries.psu.edu/catalog/15065ngp5056)
* [\[1602.02697\] Practical Black-Box Attacks against Machine Learning](https://arxiv.org/abs/1602.02697)
* [\[1806.04169\] Defense Against the Dark Arts: An overview of adversarial example security research and future research directions](https://arxiv.org/abs/1806.04169)
* [Cats to crazy quilts: Using style transfer to generate adversarial examples](https://hackernoon.com/cats-to-crazy-quilts-using-style-transfer-to-generate-adversarial-examples-b88eef073d04)
* [\[1806.11146\] Adversarial Reprogramming of Neural Networks](https://arxiv.org/abs/1806.11146)
* [Making Machine Learning Robust Against Adversarial Inputs \| July 2018 \| Communications of the ACM](https://cacm.acm.org/magazines/2018/7/229030-making-machine-learning-robust-against-adversarial-inputs/fulltext)
* \*\*\*\*[**Exploring Adversarial Reprogramming – Rajat's Blog – A blog about machine learning and math.**](https://rajatvd.github.io/Exploring-Adversarial-Reprogramming/)\*\*\*\*
* [\[1807.06732\] Motivating the Rules of the Game for Adversarial Example Research](https://arxiv.org/abs/1807.06732)
* [Breaking things is easy \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2016/12/16/breaking-things-is-easy.html)
* [Is attacking machine learning easier than defending it? \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html)
* [The challenge of verification and testing of machine learning \| cleverhans-blog](http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html)
* [Getting to know a black-box model: – Towards Data Science](https://towardsdatascience.com/getting-to-know-a-black-box-model-374e180589ce)



