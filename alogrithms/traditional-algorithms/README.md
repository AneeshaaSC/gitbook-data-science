# Traditional Algorithms

[Categories of algorithms\(non exhaustive\)](https://static.coggle.it/diagram/WHeBqDIrJRk-kDDY)

## Logistic Regression

* [The Logistic Regression Algorithm](https://towardsdatascience.com/the-logistic-regression-algorithm-75fe48e21cfa)

## Tree

* [A Practical Guide to Tree Based Learning Algorithms](https://sadanand-singh.github.io/posts/treebasedmodels)
* [Implementing sci-kit learnâ€™s Random Forest Classifier for the first time](http://joshlawman.com/implementing-the-random-forest-classifier-from-sci-kit-learn/)
* [Decision Trees for Classification](http://www.lewisgavin.co.uk/Machine-Learning-Decision-Tree/)
* [Random Forests\(r\), Explained](https://www.kdnuggets.com/2017/10/random-forests-explained.html)
* [A Practical Guide to Tree Based Learning Algorithms](https://sadanand-singh.github.io/posts/treebasedmodels/)
* [Interpreting Decision Trees and Random Forests](http://engineering.pivotal.io/post/interpreting-decision-trees-and-random-forests/)
* [A Guide to Gradient Boosted Trees with XGBoost in Python](https://jessesw.com/XG-Boost/)
* [All you need to know about Decision Tree \(Part-1\)](https://analyticsdefined.com/decision-tree-part-1/)

## SVM

* [Support Vector Machine \(SVM\) Tutorial](https://blog.statsbot.co/support-vector-machines-tutorial-c1618e635e93)

## kNN

### Disadvantage

Linear regression can extrapolate the ends but kNN can't:

![](../../.gitbook/assets/image%20%2821%29.png)



## Naive Bayes

[6 Easy Steps to Learn Naive Bayes Algorithm \(with code in Python\)](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)

