# Evaluating Models

## Problem of accuracy

[Jason Brownlee](https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/):

> Consider, for interest, the problem of screening for a relatively rare condition such as cervical cancer, which has a prevalence of about 10% \(actual stats\). If a lazy Pap smear screener was to classify every slide they see as “normal”, they would have a 90% accuracy. Very impressive! But that figure completely ignores the fact that the 10% of women who do have the disease have not been diagnosed at all.

[7 Important Model Evaluation Error Metrics Everyone should know](https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/)

