# NLP

[How to solve 90% of NLP problems: a step-by-step guide](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e)



According to [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding):

> Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing \(NLP\) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.

Further readings:[https://www.quora.com/What-does-the-word-embedding-mean-in-the-context-of-Machine-Learning/answer/Julien-Despois](https://www.quora.com/What-does-the-word-embedding-mean-in-the-context-of-Machine-Learning/answer/Julien-Despois)[https://www.tensorflow.org/tutorials/word2vec\#motivation\_why\_learn\_word\_embeddings](https://www.tensorflow.org/tutorials/word2vec#motivation_why_learn_word_embeddings)[https://www.zhihu.com/question/32275069](https://www.zhihu.com/question/32275069)

